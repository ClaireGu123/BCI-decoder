name:  'CLIP'

activation_dropout: 0.5
attention_dropout: 0.1

conv_bias: false

conv_dim:
  - 512
  - 512
 # - 512

conv_kernel:
#  - 5
  - 3
  - 2

conv_stride:
#  - 3
#  - 1
  - 2
  - 1

ctc_loss_reduction: 'sum'

feat_extract_activation: 'gelu'
feat_extract_dropout: 0.0
feat_proj_dropout: 0.1
feat_extract_norm: 'layer'
feat_quantizer_dropout: 0.0
fianl_dropout: 0.1
gradient_checkpointing: false
hidden_act: 'gelu'
hidden_size: 768  # input to the attention layer
hidden_dropout: 0.1
in_channels: 256
initializer_range: 0.02
intermediate_size: 3072
layer_norm_eps: 1e-12
layerdrop: 0.0
mask_feature_prob: 0.0
num_conv_pos_embeddings: 128
num_conv_pos_embedding_groups: 16
num_attention_heads: 16
num_hidden_layers: 6
num_frames: 700
n_classes: 41
#n_conv_layers: 3
n_conv_layers: 2
output_attentions: false
output_hidden_states: false
reg: 0.005
text_embedding_dim: 768
use_return_dict: false



